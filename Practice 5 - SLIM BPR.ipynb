{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2017/18\n",
    "\n",
    "### Practice 5 - SLIM BPR\n",
    "\n",
    "\n",
    "### State of the art machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few info about gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.optimize import fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Gradient descent</b>, also known as <b>steepest descent</b>, is an optimization algorithm for finding the local minimum of a function. To find a local minimum, the function \"steps\" in the  direction of the negative of the gradient. <b>Gradient ascent</b> is the same as gradient descent, except that it steps in the direction of the positive of the gradient and therefore finds local maximums instead of minimums. The algorithm of gradient descent can be outlined as follows:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; 1: &nbsp; Choose initial guess $x_0$ <br>\n",
    "&nbsp;&nbsp;&nbsp;    2: &nbsp; <b>for</b> k = 0, 1, 2, ... <b>do</b> <br>\n",
    "&nbsp;&nbsp;&nbsp;    3:   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $s_k$ = -$\\nabla f(x_k)$ <br>\n",
    "&nbsp;&nbsp;&nbsp;    4:   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; choose $\\alpha_k$ to minimize $f(x_k+\\alpha_k s_k)$ <br>\n",
    "&nbsp;&nbsp;&nbsp;    5:   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{k+1} = x_k + \\alpha_k s_k$ <br>\n",
    "&nbsp;&nbsp;&nbsp;    6: &nbsp;  <b>end for</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple example, let's find a local minimum for the function $f(x) = x^3-2x^2+2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108cf2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-1,2.5,1000)\n",
    "plt.plot(x,f(x))\n",
    "plt.xlim([-1,2.5])\n",
    "plt.ylim([0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from plot above that our local minimum is gonna be near around 1.4 or 1.5 (on the x-axis), but let's pretend that we don't know that, so we set our starting point (arbitrarily, in this case) at $x_0 = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local minimum occurs at: 1.33\n",
      "Number of steps: 17\n"
     ]
    }
   ],
   "source": [
    "x_old = 0\n",
    "x_new = 2 # The algorithm starts at x=2\n",
    "n_k = 0.1 # step size\n",
    "precision = 0.0001\n",
    "\n",
    "x_list, y_list = [x_new], [f(x_new)]\n",
    "\n",
    "# returns the value of the derivative of our function\n",
    "def f_gradient(x):\n",
    "    return 3*x**2-4*x\n",
    " \n",
    "while abs(x_new - x_old) > precision:\n",
    "    \n",
    "    x_old = x_new\n",
    "    \n",
    "    # Gradient descent step\n",
    "    s_k = -f_gradient(x_old)\n",
    "    \n",
    "    x_new = x_old + n_k * s_k\n",
    "    \n",
    "    x_list.append(x_new)\n",
    "    y_list.append(f(x_new))\n",
    "    \n",
    "print (\"Local minimum occurs at: {:.2f}\".format(x_new))\n",
    "print (\"Number of steps:\", len(x_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures below show the route that was taken to find the local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAADSCAYAAACIG474AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPLFyzjnnnIsST6ycc84556Lk/wFDJFn9zXXpjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1092605c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,3])\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_list,y_list,c=\"r\")\n",
    "plt.plot(x_list,y_list,c=\"r\")\n",
    "plt.plot(x,f(x), c=\"b\")\n",
    "plt.xlim([-1,2.5])\n",
    "plt.ylim([0,3])\n",
    "plt.title(\"Gradient descent\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_list,y_list,c=\"r\")\n",
    "plt.plot(x_list,y_list,c=\"r\")\n",
    "plt.plot(x,f(x), c=\"b\")\n",
    "plt.xlim([1.2,2.1])\n",
    "plt.ylim([0,3])\n",
    "plt.title(\"Gradient descent (zoomed in)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement SLIM BPR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to implement a SLIM BPR we need to:\n",
    "#### Randomly sample the triplets (user, positive_item, negative_item)\n",
    "#### Compute the score of each triplet\n",
    "#### Update the similarity matrix\n",
    "\n",
    "#### To simplify, we use a smaller dataset. More info on how to handle a bigger one later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens10MReader: loading data...\n",
      "Processed 1000000 cells\n",
      "Processed 2000000 cells\n",
      "Processed 3000000 cells\n",
      "Processed 4000000 cells\n",
      "Processed 5000000 cells\n",
      "Processed 6000000 cells\n",
      "Processed 7000000 cells\n",
      "Processed 8000000 cells\n",
      "Processed 1000000 cells\n"
     ]
    }
   ],
   "source": [
    "from Movielens10MReader import Movielens10MReader\n",
    "\n",
    "dataReader = Movielens10MReader()\n",
    "\n",
    "URM_train = dataReader.get_URM_train()\n",
    "URM_test = dataReader.get_URM_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<71568x5000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 6772272 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train = URM_train[:,0:5000]\n",
    "URM_test = URM_test[:,0:5000]\n",
    "URM_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Sampling\n",
    "\n",
    "#### Create a mask of positive interactions. How to build it depends on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<71568x5000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3917090 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_mask = URM_train.copy()\n",
    "URM_mask.data[URM_mask.data <= 3] = 0\n",
    "\n",
    "URM_mask.eliminate_zeros()\n",
    "URM_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = URM_mask.shape[0]\n",
    "n_items = URM_mask.shape[1]\n",
    "\n",
    "\n",
    "# Extract users having at least one interaction to choose from\n",
    "eligibleUsers = []\n",
    "\n",
    "for user_id in range(n_users):\n",
    "\n",
    "    start_pos = URM_mask.indptr[user_id]\n",
    "    end_pos = URM_mask.indptr[user_id+1]\n",
    "\n",
    "    if len(URM_mask.indices[start_pos:end_pos]) > 0:\n",
    "        eligibleUsers.append(user_id)\n",
    "                \n",
    "                \n",
    "\n",
    "def sampleTriplet():\n",
    "    \n",
    "    # By randomly selecting a user in this way we could end up \n",
    "    # with a user with no interactions\n",
    "    #user_id = np.random.randint(0, n_users)\n",
    "    \n",
    "    user_id = np.random.choice(eligibleUsers)\n",
    "    \n",
    "    # Get user seen items and choose one\n",
    "    userSeenItems = URM_mask[user_id,:].indices\n",
    "    pos_item_id = np.random.choice(userSeenItems)\n",
    "\n",
    "    negItemSelected = False\n",
    "\n",
    "    # It's faster to just try again then to build a mapping of the non-seen items\n",
    "    while (not negItemSelected):\n",
    "        neg_item_id = np.random.randint(0, n_items)\n",
    "\n",
    "        if (neg_item_id not in userSeenItems):\n",
    "            \n",
    "            negItemSelected = True\n",
    "\n",
    "    return user_id, pos_item_id, neg_item_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66445, 4757, 4755)\n",
      "(41302, 319, 2598)\n",
      "(49633, 1610, 2262)\n",
      "(16192, 588, 2202)\n",
      "(65856, 1552, 3458)\n",
      "(42391, 253, 3074)\n",
      "(13967, 448, 1257)\n",
      "(54368, 4226, 1156)\n",
      "(71198, 2271, 1184)\n",
      "(16717, 3638, 4065)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(sampleTriplet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Computing prediction\n",
    "\n",
    "#### The prediction depends on the model: SLIM, Matrix Factorization... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to initialize our model. In case of SLIM it works best to initialize S as zero, in case of MF you cannot because of how the gradient is computed and you have to initialize at random. Here we initialize SLIM at random just so that we have some numbers to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_matrix = np.zeros((n_items,n_items))\n",
    "\n",
    "similarity_matrix = np.random.random((n_items,n_items))\n",
    "similarity_matrix[np.arange(n_items),np.arange(n_items)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id, positive_item_id, negative_item_id = sampleTriplet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,   95,  251,  349,  353,  380,  474,  589,  733,  780, 1049,\n",
       "       1210, 1356, 1377, 1573, 1580, 1610, 2023, 2353], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userSeenItems = URM_mask[user_id,:].indices\n",
    "userSeenItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_i is 7.66, x_j is 11.26\n"
     ]
    }
   ],
   "source": [
    "x_i = similarity_matrix[positive_item_id, userSeenItems].sum()\n",
    "x_j = similarity_matrix[negative_item_id, userSeenItems].sum()\n",
    "\n",
    "print(\"x_i is {:.2f}, x_j is {:.2f}\".format(x_i, x_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Computing gradient\n",
    "\n",
    "#### The gradient depends on the objective function: RMSE, BPR... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5994703722455261"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ij = x_i - x_j\n",
    "x_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The original BPR paper uses the logarithm of the sigmoid of x_ij, whose derivative is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97338929113738248"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = 1 / (1 + np.exp(x_ij))\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Update model\n",
    "\n",
    "#### How to update depends on the model itself, here we have just one paramether, the similarity matrix, so we perform just one update. In matrix factorization we have two.\n",
    "\n",
    "#### We need a learning rate, which influences how fast the model will change. Small ones lead to slower convergence but often higher results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "similarity_matrix[positive_item_id, userSeenItems] += learning_rate * gradient\n",
    "similarity_matrix[positive_item_id, positive_item_id] = 0\n",
    "\n",
    "similarity_matrix[negative_item_id, userSeenItems] -= learning_rate * gradient\n",
    "similarity_matrix[negative_item_id, negative_item_id] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usually there is no relevant change in the scores over a single iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_i is 7.67, x_j is 11.24\n"
     ]
    }
   ],
   "source": [
    "x_i = similarity_matrix[positive_item_id, userSeenItems].sum()\n",
    "x_j = similarity_matrix[negative_item_id, userSeenItems].sum()\n",
    "\n",
    "print(\"x_i is {:.2f}, x_j is {:.2f}\".format(x_i, x_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Write the iterative epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epochIteration():\n",
    "\n",
    "    # Get number of available interactions\n",
    "    numPositiveIteractions = int(URM_mask.nnz*0.01)\n",
    "\n",
    "    start_time_epoch = time.time()\n",
    "    start_time_batch = time.time()\n",
    "\n",
    "    # Uniform user sampling without replacement\n",
    "    for num_sample in range(numPositiveIteractions):\n",
    "\n",
    "        # Sample\n",
    "        user_id, positive_item_id, negative_item_id = sampleTriplet()\n",
    "        \n",
    "        userSeenItems = URM_mask[user_id,:].indices\n",
    "        \n",
    "        # Prediction\n",
    "        x_i = similarity_matrix[positive_item_id, userSeenItems].sum()\n",
    "        x_j = similarity_matrix[negative_item_id, userSeenItems].sum()\n",
    "        \n",
    "        # Gradient\n",
    "        x_ij = x_i - x_j\n",
    "\n",
    "        gradient = 1 / (1 + np.exp(x_ij))\n",
    "        \n",
    "        # Update\n",
    "        similarity_matrix[positive_item_id, userSeenItems] += learning_rate * gradient\n",
    "        similarity_matrix[positive_item_id, positive_item_id] = 0\n",
    "\n",
    "        similarity_matrix[negative_item_id, userSeenItems] -= learning_rate * gradient\n",
    "        similarity_matrix[negative_item_id, negative_item_id] = 0\n",
    "        \n",
    "\n",
    "        if(time.time() - start_time_batch >= 30 or num_sample == numPositiveIteractions-1):\n",
    "            print(\"Processed {} ( {:.2f}% ) in {:.2f} seconds. Sample per second: {:.0f}\".format(\n",
    "                num_sample,\n",
    "                100.0* float(num_sample)/numPositiveIteractions,\n",
    "                time.time() - start_time_batch,\n",
    "                float(num_sample) / (time.time() - start_time_epoch)))\n",
    "\n",
    "\n",
    "            start_time_batch = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3316 ( 8.47% ) in 30.00 seconds. Sample per second: 111\n",
      "Processed 6620 ( 16.90% ) in 30.00 seconds. Sample per second: 110\n",
      "Processed 11208 ( 28.61% ) in 30.00 seconds. Sample per second: 125\n",
      "Processed 14764 ( 37.69% ) in 30.01 seconds. Sample per second: 123\n",
      "Processed 19150 ( 48.89% ) in 30.00 seconds. Sample per second: 128\n",
      "Processed 23422 ( 59.80% ) in 30.00 seconds. Sample per second: 130\n",
      "Processed 27067 ( 69.10% ) in 30.00 seconds. Sample per second: 129\n",
      "Processed 30713 ( 78.41% ) in 30.01 seconds. Sample per second: 128\n",
      "Processed 34807 ( 88.86% ) in 30.00 seconds. Sample per second: 129\n",
      "Processed 38401 ( 98.04% ) in 30.00 seconds. Sample per second: 128\n",
      "Processed 39169 ( 100.00% ) in 5.54 seconds. Sample per second: 128\n"
     ]
    }
   ],
   "source": [
    "epochIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "\n",
    "def similarityMatrixTopK(item_weights, forceSparseOutput = True, k=100, verbose = False, inplace=True):\n",
    "    \"\"\"\n",
    "    The function selects the TopK most similar elements, column-wise\n",
    "\n",
    "    :param item_weights:\n",
    "    :param forceSparseOutput:\n",
    "    :param k:\n",
    "    :param verbose:\n",
    "    :param inplace: Default True, WARNING matrix will be modified\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    assert (item_weights.shape[0] == item_weights.shape[1]), \"selectTopK: ItemWeights is not a square matrix\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Generating topK matrix\")\n",
    "\n",
    "    nitems = item_weights.shape[1]\n",
    "    k = min(k, nitems)\n",
    "\n",
    "    # for each column, keep only the top-k scored items\n",
    "    sparse_weights = not isinstance(item_weights, np.ndarray)\n",
    "\n",
    "    if not sparse_weights:\n",
    "\n",
    "        idx_sorted = np.argsort(item_weights, axis=0)  # sort data inside each column\n",
    "\n",
    "        if inplace:\n",
    "            W = item_weights\n",
    "        else:\n",
    "            W = item_weights.copy()\n",
    "\n",
    "        # index of the items that don't belong to the top-k similar items of each column\n",
    "        not_top_k = idx_sorted[:-k, :]\n",
    "        # use numpy fancy indexing to zero-out the values in sim without using a for loop\n",
    "        W[not_top_k, np.arange(nitems)] = 0.0\n",
    "\n",
    "        if forceSparseOutput:\n",
    "            W_sparse = sps.csr_matrix(W, shape=(nitems, nitems))\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Sparse TopK matrix generated in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "            return W_sparse\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Dense TopK matrix generated in {:.2f} seconds\".format(time.time()-start_time))\n",
    "\n",
    "        return W\n",
    "\n",
    "    else:\n",
    "        # iterate over each column and keep only the top-k similar items\n",
    "        data, rows_indices, cols_indptr = [], [], []\n",
    "\n",
    "        item_weights = check_matrix(item_weights, format='csc', dtype=np.float32)\n",
    "\n",
    "        for item_idx in range(nitems):\n",
    "\n",
    "            cols_indptr.append(len(data))\n",
    "\n",
    "            start_position = item_weights.indptr[item_idx]\n",
    "            end_position = item_weights.indptr[item_idx+1]\n",
    "\n",
    "            column_data = item_weights.data[start_position:end_position]\n",
    "            column_row_index = item_weights.indices[start_position:end_position]\n",
    "\n",
    "            idx_sorted = np.argsort(column_data)  # sort by column\n",
    "            top_k_idx = idx_sorted[-k:]\n",
    "\n",
    "            data.extend(column_data[top_k_idx])\n",
    "            rows_indices.extend(column_row_index[top_k_idx])\n",
    "\n",
    "\n",
    "        cols_indptr.append(len(data))\n",
    "\n",
    "        # During testing CSR is faster\n",
    "        W_sparse = sps.csc_matrix((data, rows_indices, cols_indptr), shape=(nitems, nitems), dtype=np.float32)\n",
    "        W_sparse = W_sparse.tocsr()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Sparse TopK matrix generated in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "        return W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLIM_BPR_Recommender(object):\n",
    "    \"\"\" SLIM_BPR recommender with cosine similarity and no shrinkage\"\"\"\n",
    "\n",
    "    def __init__(self, URM, learning_rate = 0.01, epochs = 10):\n",
    "        self.URM = URM\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.similarity_matrix = np.zeros((n_items,n_items))\n",
    "        \n",
    "        self.URM_mask = self.URM.copy()\n",
    "        self.URM_mask.data[self.URM_mask.data <= 3] = 0\n",
    "        self.URM_mask.eliminate_zeros()\n",
    "        \n",
    "        self.n_users = URM_mask.shape[0]\n",
    "        self.n_items = URM_mask.shape[1]\n",
    "\n",
    "\n",
    "        # Extract users having at least one interaction to choose from\n",
    "        self.eligibleUsers = []\n",
    "\n",
    "        for user_id in range(n_users):\n",
    "\n",
    "            start_pos = self.URM_mask.indptr[user_id]\n",
    "            end_pos = self.URM_mask.indptr[user_id+1]\n",
    "\n",
    "            if len(self.URM_mask.indices[start_pos:end_pos]) > 0:\n",
    "                self.eligibleUsers.append(user_id)\n",
    "\n",
    "\n",
    "\n",
    "    def sampleTriplet(self):\n",
    "\n",
    "        # By randomly selecting a user in this way we could end up \n",
    "        # with a user with no interactions\n",
    "        #user_id = np.random.randint(0, n_users)\n",
    "\n",
    "        user_id = np.random.choice(self.eligibleUsers)\n",
    "\n",
    "        # Get user seen items and choose one\n",
    "        userSeenItems = URM_mask[user_id,:].indices\n",
    "        pos_item_id = np.random.choice(userSeenItems)\n",
    "\n",
    "        negItemSelected = False\n",
    "\n",
    "        # It's faster to just try again then to build a mapping of the non-seen items\n",
    "        while (not negItemSelected):\n",
    "            neg_item_id = np.random.randint(0, n_items)\n",
    "\n",
    "            if (neg_item_id not in userSeenItems):\n",
    "\n",
    "                negItemSelected = True\n",
    "\n",
    "        return user_id, pos_item_id, neg_item_id\n",
    "\n",
    "\n",
    "        \n",
    "    def epochIteration(self):\n",
    "\n",
    "        # Get number of available interactions\n",
    "        numPositiveIteractions = int(self.URM_mask.nnz*0.01)\n",
    "\n",
    "        start_time_epoch = time.time()\n",
    "        start_time_batch = time.time()\n",
    "\n",
    "        # Uniform user sampling without replacement\n",
    "        for num_sample in range(numPositiveIteractions):\n",
    "\n",
    "            # Sample\n",
    "            user_id, positive_item_id, negative_item_id = self.sampleTriplet()\n",
    "\n",
    "            userSeenItems = self.URM_mask[user_id,:].indices\n",
    "\n",
    "            # Prediction\n",
    "            x_i = self.similarity_matrix[positive_item_id, userSeenItems].sum()\n",
    "            x_j = self.similarity_matrix[negative_item_id, userSeenItems].sum()\n",
    "\n",
    "            # Gradient\n",
    "            x_ij = x_i - x_j\n",
    "\n",
    "            gradient = 1 / (1 + np.exp(x_ij))\n",
    "\n",
    "            # Update\n",
    "            self.similarity_matrix[positive_item_id, userSeenItems] += learning_rate * gradient\n",
    "            self.similarity_matrix[positive_item_id, positive_item_id] = 0\n",
    "\n",
    "            self.similarity_matrix[negative_item_id, userSeenItems] -= learning_rate * gradient\n",
    "            self.similarity_matrix[negative_item_id, negative_item_id] = 0\n",
    "\n",
    "\n",
    "            if(time.time() - start_time_batch >= 30 or num_sample == numPositiveIteractions-1):\n",
    "                print(\"Processed {} ( {:.2f}% ) in {:.2f} seconds. Sample per second: {:.0f}\".format(\n",
    "                    num_sample,\n",
    "                    100.0* float(num_sample)/numPositiveIteractions,\n",
    "                    time.time() - start_time_batch,\n",
    "                    float(num_sample) / (time.time() - start_time_epoch)))\n",
    "\n",
    "                start_time_batch = time.time()\n",
    "\n",
    "                \n",
    "    def fit(self):\n",
    "        \n",
    "        for numEpoch in range(self.epochs):\n",
    "            self.epochIteration()\n",
    "            \n",
    "        self.similarity_matrix = self.similarity_matrix.T\n",
    "        \n",
    "        self.similarity_matrix = similarityMatrixTopK(self.similarity_matrix, k=100)\n",
    "        \n",
    "        \n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        \n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.URM[user_id]\n",
    "        scores = user_profile.dot(self.similarity_matrix)\n",
    "        scores = scores.toarray()\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1].squeeze()\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "            \n",
    "        return ranking[:at]\n",
    "    \n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.URM[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3159 ( 8.06% ) in 30.00 seconds. Sample per second: 105\n",
      "Processed 5365 ( 13.70% ) in 30.01 seconds. Sample per second: 89\n",
      "Processed 9164 ( 23.40% ) in 30.00 seconds. Sample per second: 102\n",
      "Processed 13858 ( 35.38% ) in 30.00 seconds. Sample per second: 115\n",
      "Processed 18138 ( 46.31% ) in 30.02 seconds. Sample per second: 121\n",
      "Processed 22812 ( 58.24% ) in 30.01 seconds. Sample per second: 127\n",
      "Processed 27464 ( 70.11% ) in 30.01 seconds. Sample per second: 131\n",
      "Processed 31604 ( 80.68% ) in 30.00 seconds. Sample per second: 132\n",
      "Processed 36215 ( 92.46% ) in 30.01 seconds. Sample per second: 134\n",
      "Processed 39169 ( 100.00% ) in 18.37 seconds. Sample per second: 136\n"
     ]
    }
   ],
   "source": [
    "recommender = SLIM_BPR_Recommender(URM_train, epochs=1)\n",
    "recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommender_object, at=5):\n",
    "    \n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "\n",
    "\n",
    "    for user_id in range(URM_test.shape[0]):\n",
    "        \n",
    "        if user_id % 10000 == 0:\n",
    "            print(\"Processed user: {} \".format(user_id))\n",
    "\n",
    "        relevant_items = URM_test[user_id].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommender_object.recommend(user_id, at=at)\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user: 0 \n",
      "Processed user: 10000 \n",
      "Processed user: 20000 \n",
      "Processed user: 30000 \n",
      "Processed user: 40000 \n",
      "Processed user: 50000 \n",
      "Processed user: 60000 \n",
      "Processed user: 70000 \n",
      "Recommender performance is: Precision = 0.0007, Recall = 0.0001, MAP = 0.0002\n"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm(URM_test, recommender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horrible performance!!!\n",
    "#### Of course, we initialized the model as zero and performed just one epoch on a micro-subsample of the data. Being a machine learning approach, more time is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the cython impementation and run some serious learning. Here I show just two epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data\n",
      "Data info:\n",
      "Unique tracks count: 100000\n",
      "Unique playlist count: 57561\n",
      "Target tracks count: 32195\n",
      "Target playlists count: 10000\n",
      "tracks_tags (483501, 2)\n",
      "  track_id     tag\n",
      "0  2972914   54087\n",
      "1  2972914    1757\n",
      "2  2972914    1718\n",
      "3  2972914  116712\n",
      "4  2972914  189631\n",
      "0  2750239  189631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2cb582c4687a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrun_me\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_SLIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/Polimi/RecSys/comp/run_me.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSLIM_BPR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSLIM_BPR_Cython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSLIM_BPR_Cython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMovielens10MReader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMovielens10MReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/Polimi/RecSys/comp/SLIM_BPR.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_album\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mtracks_albums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_track_album\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'album'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_final\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tracks_albums {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_albums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_albums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/Polimi/RecSys/comp/SLIM_BPR.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_album\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mtracks_albums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_track_album\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'album'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_final\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tracks_albums {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_albums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_albums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     mgr = _arrays_to_mgr(arrays, columns, index, columns,\n\u001b[0;32m--> 327\u001b[0;31m                                          dtype=dtype)\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5504\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4309\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4310\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4311\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4381\u001b[0;31m         \u001b[0mint_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4382\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_multi_blockify\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4450\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4452\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4453\u001b[0m         \u001b[0mnew_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2717\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmgr_locs\u001b[0;34m(self, new_mgr_locs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmgr_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.BlockPlacement.__init__ (pandas/_libs/lib.c:29179)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(a, dtype, requirements)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequirements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from run_me import run_SLIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you see is:\n",
    "* The initial performance with the model initialized as zero\n",
    "* The performance after the first iteration\n",
    "\n",
    "### Compared to content and collaborative k-nearest neighbor SLIM improves map significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
