{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION = False\n",
    "SUBMISSION_FILENAME = 'submission.csv'\n",
    "TEST_FILENAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data\n"
     ]
    }
   ],
   "source": [
    "target_playlists = pd.read_csv('datasets/target_playlists.csv', sep='\\t')\n",
    "target_tracks = pd.read_csv('datasets/target_tracks.csv', sep='\\t')\n",
    "tracks_final = pd.read_csv('datasets/tracks_final.csv', sep='\\t')\n",
    "playlists_final = pd.read_csv('datasets/playlists_final.csv', sep='\\t')\n",
    "train_final = pd.read_csv('datasets/train_final.csv', sep='\\t')\n",
    "\n",
    "print('Successfully read data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "Unique tracks count: 100000\n",
      "Unique playlist count: 57561\n",
      "Target tracks count: 32195\n",
      "Target playlists count: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Data info:')\n",
    "print('Unique tracks count: {}'.format(tracks_final['track_id'].nunique()))\n",
    "print('Unique playlist count: {}'.format(playlists_final['playlist_id'].nunique()))\n",
    "print('Target tracks count: {}'.format(target_tracks['track_id'].nunique()))\n",
    "print('Target playlists count: {}'.format(target_playlists['playlist_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_tags_to_list(str_tags):\n",
    "    if str_tags == '[]':\n",
    "        return []\n",
    "    return list(map(int, str_tags.replace('[', '').replace(']', '').replace(' ', '').split(',')))\n",
    "\n",
    "\n",
    "def str_album_to_int(album):\n",
    "    if album == '[]' or album == '[None]':\n",
    "        return -1\n",
    "    return int(album.replace('[', '').replace(']', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_tags (483501, 2)\n",
      "  track_id     tag\n",
      "0  2972914   54087\n",
      "1  2972914    1757\n",
      "2  2972914    1718\n",
      "3  2972914  116712\n",
      "4  2972914  189631\n",
      "0  2750239  189631\n"
     ]
    }
   ],
   "source": [
    "def get_tracks_tags(track_final):\n",
    "    track_tags_list = str_tags_to_list(track_final['tags'])\n",
    "    return [[track_final['track_id'], track_tag] for track_tag in track_tags_list]\n",
    "\n",
    "tracks_tags = pd.concat([pd.DataFrame(data=get_tracks_tags(track_final), columns=['track_id', 'tag']) for index, track_final in tracks_final.iterrows()])\n",
    "print('tracks_tags {}'.format(tracks_tags.shape))\n",
    "print(tracks_tags.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_albums (100000, 2)\n",
      "   track_id  album\n",
      "0   2972914      7\n",
      "0   2750239      8\n",
      "0   1550729      9\n",
      "0   2169950      9\n",
      "0   1903709     -1\n",
      "0   2256817      9\n"
     ]
    }
   ],
   "source": [
    "def get_track_album(track_final):\n",
    "    track_album = str_album_to_int(track_final['album'])\n",
    "    return [[track_final['track_id'], track_album]]\n",
    "\n",
    "tracks_albums = pd.concat([pd.DataFrame(data=get_track_album(track_final), columns=['track_id', 'album']) for index, track_final in tracks_final.iterrows()])\n",
    "print('tracks_albums {}'.format(tracks_albums.shape))\n",
    "print(tracks_albums.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_albums (73244, 2)\n",
      "   track_id  album\n",
      "0   2972914      7\n",
      "0   2750239      8\n",
      "0   1550729      9\n",
      "0   2169950      9\n",
      "0   2256817      9\n",
      "0   2561768     26\n"
     ]
    }
   ],
   "source": [
    "# Remove tracks without album\n",
    "tracks_albums = tracks_albums[tracks_albums.album != -1]\n",
    "print('tracks_albums {}'.format(tracks_albums.shape))\n",
    "print(tracks_albums.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_titles (108382, 2)\n",
      "  playlist_id  title\n",
      "0      644838  12727\n",
      "0     3120683    183\n",
      "0     4278112  12389\n",
      "1     4278112  18698\n",
      "2     4278112  18925\n",
      "3     4278112  11695\n"
     ]
    }
   ],
   "source": [
    "def get_playlist_titles(playlist_final):\n",
    "    playlist_tags_list = str_tags_to_list(playlist_final['title'])\n",
    "    return [[playlist_final['playlist_id'], playlist_tag] for playlist_tag in playlist_tags_list]\n",
    "\n",
    "playlist_titles = pd.concat([pd.DataFrame(data=get_playlist_titles(playlist_final), columns=['playlist_id', 'title']) for index, playlist_final in playlists_final.iterrows()])\n",
    "print('playlist_titles {}'.format(playlist_titles.shape))\n",
    "print(playlist_titles.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_artist (100000, 2)\n",
      "   track_id  artist_id\n",
      "0   2972914        144\n",
      "1   2750239        246\n",
      "2   1550729        144\n",
      "3   2169950        144\n",
      "4   1903709        144\n",
      "5   2256817        144\n"
     ]
    }
   ],
   "source": [
    "tracks_artist = pd.DataFrame()\n",
    "tracks_artist['track_id'] = tracks_final['track_id']\n",
    "tracks_artist['artist_id'] = tracks_final['artist_id']\n",
    "print('tracks_artist {}'.format(tracks_artist.shape))\n",
    "print(tracks_artist.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks with album count: 73244\n",
      "Unique album count: 27604\n",
      "\n",
      "Tracks with tags count: 97211\n",
      "Unique tags count: 31900\n",
      "\n",
      "Tracks with artists count: 100000\n",
      "Unique artists count: 17536\n",
      "\n",
      "Playlists with title count: 52384\n",
      "Unique titles count: 21064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Tracks with album count: {}'.format(tracks_albums['track_id'].nunique()))\n",
    "print('Unique album count: {}\\n'.format(tracks_albums['album'].nunique()))\n",
    "\n",
    "print('Tracks with tags count: {}'.format(tracks_tags['track_id'].nunique()))\n",
    "print('Unique tags count: {}\\n'.format(tracks_tags['tag'].nunique()))\n",
    "\n",
    "print('Tracks with artists count: {}'.format(tracks_artist['track_id'].nunique()))\n",
    "print('Unique artists count: {}\\n'.format(tracks_artist['artist_id'].nunique()))\n",
    "\n",
    "print('Playlists with title count: {}'.format(playlist_titles['playlist_id'].nunique()))\n",
    "print('Unique titles count: {}\\n'.format(playlist_titles['title'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2972914, 2750239, 1550729, 2169950, 1903709, 2256817]\n",
      "track_id_le classes: 100000\n",
      "[77187 77187 77187 77187 77187 69189]\n",
      "[54087, 1757, 1718, 116712, 189631, 189631]\n",
      "tags_le classes: 31900\n",
      "[ 6683   257   254 13977 22350 22350]\n",
      "  track_id     tag  transformed_track_id  transformed_tag\n",
      "0  2972914   54087                 77187             6683\n",
      "1  2972914    1757                 77187              257\n",
      "2  2972914    1718                 77187              254\n",
      "3  2972914  116712                 77187            13977\n",
      "4  2972914  189631                 77187            22350\n",
      "0  2750239  189631                 69189            22350\n"
     ]
    }
   ],
   "source": [
    "print(list(tracks_final['track_id'])[:6])\n",
    "track_id_le = preprocessing.LabelEncoder()\n",
    "track_id_le.fit(list(tracks_final['track_id']))\n",
    "print('track_id_le classes: {}'.format(len(track_id_le.classes_)))\n",
    "transformed_track_id = track_id_le.transform(list(tracks_tags['track_id']))\n",
    "print(transformed_track_id[:6])\n",
    "tracks_tags['transformed_track_id'] = transformed_track_id\n",
    "\n",
    "print(list(tracks_tags['tag'])[:6])\n",
    "tags_le = preprocessing.LabelEncoder()\n",
    "tags_le.fit(list(tracks_tags['tag']))\n",
    "print('tags_le classes: {}'.format(len(tags_le.classes_)))\n",
    "transformed_tags = tags_le.transform(list(tracks_tags['tag']))\n",
    "print(transformed_tags[:6])\n",
    "tracks_tags['transformed_tag'] = transformed_tags\n",
    "\n",
    "print(tracks_tags.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album_le classes: 27604\n",
      "   track_id  album  transformed_track_id\n",
      "0   2972914  31901                 77187\n",
      "0   2750239  31902                 69189\n",
      "0   1550729  31903                 37833\n",
      "0   2169950  31903                 54261\n",
      "0   2256817  31903                 56492\n",
      "0   2561768  31905                 64072\n"
     ]
    }
   ],
   "source": [
    "album_le = preprocessing.LabelEncoder()\n",
    "album_le.fit(list(tracks_albums['album']))\n",
    "print('album_le classes: {}'.format(len(album_le.classes_)))\n",
    "tracks_albums['transformed_track_id'] = track_id_le.transform(list(tracks_albums['track_id']))\n",
    "tracks_albums['album'] = list(map(lambda x: x+31900, album_le.transform(list(tracks_albums['album']))))\n",
    "print(tracks_albums.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album_le classes: 17536\n",
      "   track_id  artist_id  transformed_track_id  transformed_artist_id\n",
      "0   2972914        144                 77187                  59506\n",
      "1   2750239        246                 69189                  59508\n",
      "2   1550729        144                 37833                  59506\n",
      "3   2169950        144                 54261                  59506\n",
      "4   1903709        144                 47181                  59506\n",
      "5   2256817        144                 56492                  59506\n"
     ]
    }
   ],
   "source": [
    "artist_le = preprocessing.LabelEncoder()\n",
    "artist_le.fit(list(tracks_artist['artist_id']))\n",
    "print('album_le classes: {}'.format(len(artist_le.classes_)))\n",
    "tracks_artist['transformed_track_id'] = track_id_le.transform(list(tracks_artist['track_id']))\n",
    "tracks_artist['transformed_artist_id'] = list(map(lambda x: x+31900+27604,\\\n",
    "                                                  artist_le.transform(list(tracks_artist['artist_id']))))\n",
    "print(tracks_artist.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playlist and tracks that belong to them\n",
    "target_playlists_and_tracks = pd.merge(target_playlists, train_final, on='playlist_id')\n",
    "print('target_playlists_and_tracks {}'.format(target_playlists_and_tracks.shape))\n",
    "print(target_playlists_and_tracks.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data(train_final, target_playlists_and_tracks, random_state):\n",
    "    validation_set = target_playlists_and_tracks.groupby(['playlist_id'])\\\n",
    "                        .apply(lambda x: x.sample(n=3, random_state=random_state))\\\n",
    "                        .reset_index(drop=True)\n",
    "    df_concat = pd.concat([train_final, validation_set])\n",
    "    training_set = df_concat.drop_duplicates(keep=False)\n",
    "    return training_set, validation_set\n",
    "\n",
    "# Split dataset - from all target playlists remove randomly 3 tracks\n",
    "training_set, validation_set = split_training_data(train_final, target_playlists_and_tracks, random_state=0)\n",
    "test_target_tracks = validation_set['track_id'].drop_duplicates(keep='first').to_frame()\n",
    "test_target_tracks['transformed_track_id'] = track_id_le.transform(list(test_target_tracks['track_id']))\n",
    "target_tracks['transformed_track_id'] = track_id_le.transform(list(target_tracks['track_id']))\n",
    "\n",
    "print('training_set: {} validation_set: {}'.format(training_set.shape, validation_set.shape))\n",
    "print(training_set.head(5))\n",
    "print('training_set: {} validation_set: {}'.format(training_set.shape, validation_set.shape))\n",
    "print(validation_set.head(5))\n",
    "print('test_target_tracks: {}'.format(test_target_tracks.shape))\n",
    "print(test_target_tracks.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_titles = pd.merge(playlist_titles, training_set, on='playlist_id')\n",
    "tracks_titles['transformed_track_id'] = track_id_le.transform(list(tracks_titles['track_id']))\n",
    "print(tracks_titles.shape)\n",
    "print(tracks_titles.head(3))\n",
    "\n",
    "ones = np.ones(tracks_titles.shape[0])\n",
    "print('ones shape: {}, vector: {}'.format(ones.shape, ones))\n",
    "tracks_with_title = scipy.sparse.coo_matrix((ones, (list(tracks_titles['transformed_track_id']), list(tracks_titles['title']))))\n",
    "tracks_with_title = tracks_with_title.tocsr()\n",
    "\n",
    "print(tracks_with_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tracks_tags.shape {}'.format(tracks_tags.shape))\n",
    "print('tracks_albums.shape {}'.format(tracks_albums.shape))\n",
    "print('tracks_artist.shape {}'.format(tracks_artist.shape))\n",
    "\n",
    "ones = np.ones(tracks_tags.shape[0] + tracks_albums.shape[0] + tracks_artist.shape[0])\n",
    "print('ones shape: {}, vector: {}'.format(ones.shape, ones))\n",
    "\n",
    "ICM_tags = scipy.sparse.coo_matrix((ones, (list(tracks_tags['transformed_track_id']) + list(tracks_albums['transformed_track_id']) + list(tracks_artist['transformed_track_id'])\\\n",
    "                                          , list(tracks_tags['transformed_tag']) + list(tracks_albums['album']) + list(tracks_artist['transformed_artist_id']))))\n",
    "ICM_tags = ICM_tags.tocsr()\n",
    "\n",
    "# Add tracks that do not have tags and its transformed id is bigger than the biggest that has a tag\n",
    "# missing_items = np.zeros((1, tracks_tags['transformed_tag'].nunique() + tracks_albums['album'].nunique() + tracks_artist['artist_id'].nunique()))\n",
    "# missing_items = scipy.sparse.csr_matrix(missing_items)\n",
    "# ICM_tags = scipy.sparse.vstack((ICM_tags, missing_items))\n",
    "\n",
    "print(ICM_tags.shape)\n",
    "features_per_item = (ICM_tags > 0).sum(axis=1)\n",
    "items_per_feature = (ICM_tags > 0).sum(axis=0)\n",
    "\n",
    "print('features_per_item.shape {}'.format(features_per_item.shape))\n",
    "print('items_per_feature.shape {}'.format(items_per_feature.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_item = np.array(features_per_item).squeeze()\n",
    "items_per_feature = np.array(items_per_feature).squeeze()\n",
    "\n",
    "print(features_per_item.shape)\n",
    "print(items_per_feature.shape)\n",
    "\n",
    "features_per_item = np.sort(features_per_item)\n",
    "items_per_feature = np.sort(items_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline  \n",
    "\n",
    "pyplot.plot(features_per_item, 'ro')\n",
    "pyplot.ylabel('Num features ')\n",
    "pyplot.xlabel('Item Index')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(items_per_feature, 'ro')\n",
    "pyplot.ylabel('Num items ')\n",
    "pyplot.xlabel('Feature Index')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMISSION:\n",
    "    train_final['count'] = train_final.groupby(['track_id']).transform('count')\n",
    "    tracks_with_popularity = train_final.groupby(['track_id', 'count']).head(1).sort_values('count', ascending=False)\n",
    "    target_tracks_with_popularity = pd.merge(target_tracks, tracks_with_popularity, on='track_id').groupby('track_id').head(1)\n",
    "    target_tracks_with_popularity = target_tracks_with_popularity.sort_values('count').reset_index()\n",
    "    print(target_tracks_with_popularity.head(5))\n",
    "else:\n",
    "    training_set['count'] = training_set.groupby(['track_id']).transform('count')\n",
    "    tracks_with_popularity = training_set.groupby(['track_id', 'count']).head(1).sort_values('count', ascending=False)\n",
    "    target_tracks_with_popularity = pd.merge(test_target_tracks, tracks_with_popularity, on='track_id').groupby('track_id').head(1)\n",
    "    target_tracks_with_popularity = target_tracks_with_popularity.sort_values('count').reset_index()\n",
    "    print(target_tracks_with_popularity.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_tracks_popularity = target_tracks_with_popularity.sort_values('count').reset_index()\n",
    "print(target_tracks_with_popularity['count'].describe())\n",
    "pyplot.plot(target_tracks_with_popularity['count'], 'ro')\n",
    "pyplot.ylabel('Popularity')\n",
    "pyplot.xlabel('Target tracks')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_sum = target_tracks_with_popularity['count'].sum()\n",
    "target_tracks_with_popularity['predictions'] = target_tracks_with_popularity['count'] / popularity_sum * 30000\n",
    "\n",
    "print(target_tracks_with_popularity.tail(5))\n",
    "print(target_tracks_with_popularity['predictions'].sum())\n",
    "\n",
    "print(target_tracks_with_popularity['predictions'].describe())\n",
    "\n",
    "def round_ceil(x):\n",
    "    x['predictions'] = int(math.ceil(x['predictions']))\n",
    "    return x\n",
    "\n",
    "def reduce_by_one(x):\n",
    "    if x['predictions'] > 1:\n",
    "        x['predictions'] = x['predictions'] - 1\n",
    "    return x\n",
    "\n",
    "target_tracks_with_predictions = target_tracks_with_popularity.apply(round_ceil, axis=1)\n",
    "to_reduce = target_tracks_with_predictions['predictions'].sum() - 30000\n",
    "\n",
    "print(target_tracks_with_predictions.tail(5))\n",
    "print(target_tracks_with_predictions['predictions'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(recommendation_item, validation_set):\n",
    "    validation_item = validation_set.loc[validation_set['playlist_id'] == recommendation_item['playlist_id']]\n",
    "    recommendation_item['recommendation'] = pd.Series(recommendation_item['recommendation'])\\\n",
    "                                                .isin(list(validation_item['track_id']))\n",
    "    return recommendation_item\n",
    "\n",
    "\n",
    "def precision(recommended_items_relevance):\n",
    "    precision_scores = recommended_items_relevance.sum(axis=1) / recommended_items_relevance.shape[1]\n",
    "    return precision_scores.mean()\n",
    "\n",
    "\n",
    "def mAP(recommended_items_relevance):\n",
    "    p_at_k = recommended_items_relevance.cumsum(axis=1) / (1 + np.arange(recommended_items_relevance.shape[1]))\n",
    "    recommended_items_mAP = p_at_k.sum(axis=1) / recommended_items_relevance.shape[1]\n",
    "    return recommended_items_mAP.mean()\n",
    "\n",
    "\n",
    "def evaluate_recommendations(recommended_items, validation_set):\n",
    "    items_relevance = recommended_items.apply(lambda recommendation_item: is_relevant(recommendation_item, validation_set), axis=1)\n",
    "    recommended_items_relevance = pd.DataFrame(list(items_relevance['recommendation']), index=items_relevance['recommendation'].index)\n",
    "    precision_score = precision(recommended_items_relevance)\n",
    "    mAP_score = mAP(recommended_items_relevance)\n",
    "    return precision_score, mAP_score\n",
    "\n",
    "def evaluate(recommended_items, validation_set):\n",
    "    print('Evaluating...')\n",
    "    begin = time.time()\n",
    "    precision_score, mAP_score = evaluate_recommendations(recommended_items, validation_set)\n",
    "    print('Precision: {0:.{digits}f}, mAP: {1:.{digits}f}, took {2:.{digits}f}s'\n",
    "          .format(precision_score, mAP_score, time.time() - begin, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, scipy.sparse.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, scipy.sparse.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, scipy.sparse.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, scipy.sparse.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, scipy.sparse.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, scipy.sparse.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, scipy.sparse.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "#         print(X.indptr)\n",
    "        \n",
    "        col_nnz = np.diff(X.indptr)\n",
    "#         print(col_nnz)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "#         print(X[:2][:2])\n",
    "#         print(norm)\n",
    "#         print(col_nnz)\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        print(\"Computing distance\")\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "#         dist = dist - scipy.sparse.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "#         print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "#         if self.shrinkage > 0:\n",
    "#             dist = self.apply_shrinkage(X, dist)\n",
    "#             print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "#         co_counts = co_counts - scipy.sparse.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Cosine()\n",
    "isim = distance.compute(ICM_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    def __init__(self, shrinkage=10, similarity='cosine'):\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "    \n",
    "    def fit(self, training_set, ICM, target_tracks, tracks_with_title, playlist_titles, items_similarity):\n",
    "        self.training_set = training_set\n",
    "#         self.items_similarity = self.distance.compute(ICM)\n",
    "        self.items_similarity = items_similarity\n",
    "        self.tracks_with_title = tracks_with_title\n",
    "        self.playlist_titles = playlist_titles\n",
    "        \n",
    "        self.target_tracks_mask = np.zeros(self.items_similarity.shape[0])\n",
    "        for value in list(target_tracks['transformed_track_id']):\n",
    "            self.target_tracks_mask[value] = 1\n",
    "    \n",
    "    def recommend(self, target_playlists):\n",
    "        def make_recommendation(playlist):\n",
    "            tracks_on_playlist = self.training_set.loc[self.training_set['playlist_id'] == playlist['playlist_id']]\n",
    "            transformed_tracks_on_playlist = track_id_le.transform(list(tracks_on_playlist['track_id']))\n",
    "            tracks_on_playlist_mask = np.ones(self.items_similarity.shape[0])\n",
    "            for value in transformed_tracks_on_playlist:\n",
    "                tracks_on_playlist_mask[value] = 0\n",
    "            \n",
    "#             titles = self.playlist_titles.loc[self.playlist_titles['playlist_id'] == playlist['playlist_id']]\n",
    "#             titles_mask = np.squeeze(np.asarray(self.tracks_with_title[:, titles['title']].sum(axis=1)))\n",
    "#             titles_mask = titles_mask / (np.amax(titles_mask)+ 1)\n",
    "#             titles_mask = np.log(np.squeeze(np.asarray(titles_mask + 3)))\n",
    "            tracks_tags_correlation = np.squeeze(np.asarray(recommender.items_similarity[:, transformed_tracks_on_playlist].sum(axis=1)))\n",
    "            tracks_tags_correlation = tracks_tags_correlation * self.target_tracks_mask\n",
    "            tracks_tags_correlation = tracks_tags_correlation * tracks_on_playlist_mask\n",
    "#             tracks_tags_correlation = tracks_tags_correlation * titles_mask\n",
    "            ind = np.argpartition(list(tracks_tags_correlation), -3)[-3:]\n",
    "    \n",
    "            recommended_tracks = track_id_le.inverse_transform(ind)\n",
    "            playlist['recommendation'] = list(reversed(recommended_tracks))\n",
    "            return playlist\n",
    "        recommended_items = target_playlists.apply(lambda playlist: make_recommendation(playlist), axis=1)\n",
    "        return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "begin = time.time()\n",
    "recommender = ContentBasedRecommender()\n",
    "recommender.fit(training_set, ICM_tags, test_target_tracks, tracks_with_title, playlist_titles, isim)\n",
    "# recommender.fit(train_final, ICM_tags, target_tracks, tracks_with_title, playlist_titles)\n",
    "print('Took {0:.{digits}f}s'.format(time.time() - begin, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-146a8467c04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recommending...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbegin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrecommended_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_playlists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Took {0:.{digits}f}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "print('Recommending...')\n",
    "begin = time.time()\n",
    "recommended_items = recommender.recommend(target_playlists.head(1))\n",
    "print('Took {0:.{digits}f}s'.format(time.time() - begin, digits=5))\n",
    "\n",
    "print('recommended_items {}'.format(recommended_items.shape))\n",
    "print(recommended_items.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Precision: 0.13667, mAP: 0.15389, took 0.28809s\n"
     ]
    }
   ],
   "source": [
    "if not SUBMISSION:\n",
    "    evaluate(recommended_items, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "   playlist_id               recommendation\n",
      "4        65078   [1675097, 1893087, 949178]\n",
      "3      4267369  [2504992, 1999966, 2062260]\n",
      "2      4891851    [557629, 3016360, 521035]\n",
      "0     10024884     [320980, 820484, 291014]\n",
      "1     10624787   [343990, 1788063, 2790769]\n",
      "5     10637124   [273502, 3358237, 3727608]\n",
      "       playlist_id  track_id\n",
      "291          65078    949178\n",
      "292          65078   2225673\n",
      "293          65078   2146602\n",
      "7587       4267369   3157456\n",
      "7588       4267369   2062260\n",
      "7589       4267369   1538115\n",
      "9357       4891851    557629\n",
      "9358       4891851      4123\n",
      "9359       4891851   1498009\n",
      "24012     10024884    471263\n",
      "24013     10024884   2773840\n",
      "24014     10024884   3481281\n",
      "26454     10624787   1913831\n",
      "26455     10624787   1104333\n",
      "26456     10624787   3219522\n",
      "26496     10637124   3358237\n",
      "26497     10637124    273502\n",
      "26498     10637124   1818594\n"
     ]
    }
   ],
   "source": [
    "print(recommended_items.shape)\n",
    "print(recommended_items.sort_values('playlist_id').head(10))\n",
    "print(validation_set.loc[validation_set['playlist_id'].isin(recommended_items['playlist_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing...\n"
     ]
    }
   ],
   "source": [
    "def print_results(recommended_items, filename):\n",
    "    print('Printing...')\n",
    "    with open('./submissions/{}'.format(filename), 'w') as output_file:\n",
    "        output_file.write('playlist_id,track_ids\\n')\n",
    "        for index, recommendation in recommended_items.iterrows():\n",
    "            row = '{},'.format(recommendation['playlist_id'])\n",
    "            for track_id in pd.Series(recommendation['recommendation']).values:\n",
    "                row += ' {}'.format(track_id)\n",
    "            row += '\\n'\n",
    "            output_file.write(row)\n",
    "print_results(recommended_items, filename=SUBMISSION_FILENAME if SUBMISSION else TEST_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
