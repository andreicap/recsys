{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION = False\n",
    "SUBMISSION_FILENAME = 'submission.csv'\n",
    "TEST_FILENAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data\n"
     ]
    }
   ],
   "source": [
    "target_playlists = pd.read_csv('../datasets/target_playlists.csv', sep='\\t')\n",
    "target_tracks = pd.read_csv('../datasets/target_tracks.csv', sep='\\t')\n",
    "tracks_final = pd.read_csv('../datasets/tracks_final.csv', sep='\\t')\n",
    "playlists_final = pd.read_csv('../datasets/playlists_final.csv', sep='\\t')\n",
    "train_final = pd.read_csv('../datasets/train_final.csv', sep='\\t')\n",
    "\n",
    "print('Successfully read data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, scipy.sparse.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, scipy.sparse.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, scipy.sparse.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, scipy.sparse.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, scipy.sparse.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, scipy.sparse.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, scipy.sparse.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_relevant(recommendation_item, validation_set):\n",
    "    validation_item = validation_set.loc[validation_set['playlist_id'] == recommendation_item['playlist_id']]\n",
    "    recommendation_item['recommendation'] = pd.Series(recommendation_item['recommendation'])\\\n",
    "                                                .isin(list(validation_item['track_id']))\n",
    "    return recommendation_item\n",
    "\n",
    "\n",
    "def precision(recommended_items_relevance):\n",
    "    precision_scores = recommended_items_relevance.sum(axis=1) / recommended_items_relevance.shape[1]\n",
    "    return precision_scores.mean()\n",
    "\n",
    "\n",
    "def mAP(recommended_items_relevance):\n",
    "    p_at_k = recommended_items_relevance.cumsum(axis=1) / (1 + np.arange(recommended_items_relevance.shape[1]))\n",
    "    recommended_items_mAP = p_at_k.sum(axis=1) / recommended_items_relevance.shape[1]\n",
    "    return recommended_items_mAP.mean()\n",
    "\n",
    "\n",
    "def evaluate_recommendations(recommended_items, validation_set):\n",
    "    items_relevance = recommended_items.apply(lambda recommendation_item: is_relevant(recommendation_item, validation_set), axis=1)\n",
    "    recommended_items_relevance = pd.DataFrame(list(items_relevance['recommendation']), index=items_relevance['recommendation'].index)\n",
    "    precision_score = precision(recommended_items_relevance)\n",
    "    mAP_score = mAP(recommended_items_relevance)\n",
    "    return precision_score, mAP_score\n",
    "\n",
    "def evaluate(recommended_items, validation_set):\n",
    "    print('Evaluating...')\n",
    "    begin = time.time()\n",
    "    precision_score, mAP_score = evaluate_recommendations(recommended_items, validation_set)\n",
    "    print('Precision: {0:.{digits}f}, mAP: {1:.{digits}f}, took {2:.{digits}f}s'\n",
    "          .format(precision_score, mAP_score, time.time() - begin, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_tags_to_list(str_tags):\n",
    "    if str_tags == '[]':\n",
    "        return []\n",
    "    return list(map(int, str_tags.replace('[', '').replace(']', '').replace(' ', '').split(',')))\n",
    "\n",
    "\n",
    "def str_album_to_int(album):\n",
    "    if album == '[]' or album == '[None]':\n",
    "        return -1\n",
    "    return int(album.replace('[', '').replace(']', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:18: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_tags (483501, 3)\n",
      "   track_id     tag  weight\n",
      "0   2972914   54087     2.5\n",
      "1   2972914    1757     2.0\n",
      "2   2972914    1718     1.6\n",
      "3   2972914  116712     1.2\n",
      "4   2972914  189631     1.0\n",
      "0   2750239  189631     2.5\n"
     ]
    }
   ],
   "source": [
    "def get_weight(i):\n",
    "    if i == 0:\n",
    "        return 2.5\n",
    "    if i == 1:\n",
    "        return 2.0\n",
    "    if i == 2:\n",
    "        return 1.6\n",
    "    if i == 3:\n",
    "        return 1.2\n",
    "    if i == 4:\n",
    "        return 1.0\n",
    "\n",
    "def get_tracks_tags(track_final):\n",
    "    track_tags_list = str_tags_to_list(track_final['tags'])\n",
    "    return [[track_final['track_id'], track_tag, get_weight(i)] for i, track_tag in enumerate(track_tags_list)]\n",
    "\n",
    "try:\n",
    "    tracks_tags = pd.DataFrame.from_csv('../datasets/tags.csv')\n",
    "except:\n",
    "    tracks_tags = pd.concat([pd.DataFrame(data=get_tracks_tags(track_final), columns=['track_id', 'tag', 'weight']) for index, track_final in tracks_final.iterrows()])\n",
    "    tracks_tags.to_csv('../datasets/tags.csv')\n",
    "\n",
    "print('tracks_tags {}'.format(tracks_tags.shape))\n",
    "print(tracks_tags.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_albums (73244, 2)\n",
      "   track_id  album\n",
      "0   2972914      7\n",
      "0   2750239      8\n",
      "0   1550729      9\n",
      "0   2169950      9\n",
      "0   2256817      9\n",
      "0   2561768     26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "def get_track_album(track_final):\n",
    "    track_album = str_album_to_int(track_final['album'])\n",
    "    return [[track_final['track_id'], track_album]]\n",
    "\n",
    "try:\n",
    "    tracks_albums = pd.DataFrame.from_csv('../datasets/albums.csv')\n",
    "except:\n",
    "    tracks_albums = pd.concat([pd.DataFrame(data=get_track_album(track_final), columns=['track_id', 'album']) for index, track_final in tracks_final.iterrows()])\n",
    "    # Remove tracks without album\n",
    "    tracks_albums = tracks_albums[tracks_albums.album != -1]\n",
    "    tracks_albums.to_csv('../datasets/albums.csv')\n",
    "\n",
    "print('tracks_albums {}'.format(tracks_albums.shape))\n",
    "print(tracks_albums.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_artist (100000, 2)\n",
      "   track_id  artist_id\n",
      "0   2972914        144\n",
      "1   2750239        246\n",
      "2   1550729        144\n",
      "3   2169950        144\n",
      "4   1903709        144\n",
      "5   2256817        144\n"
     ]
    }
   ],
   "source": [
    "tracks_artist = pd.DataFrame()\n",
    "tracks_artist['track_id'] = tracks_final['track_id']\n",
    "tracks_artist['artist_id'] = tracks_final['artist_id']\n",
    "print('tracks_artist {}'.format(tracks_artist.shape))\n",
    "print(tracks_artist.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_titles (108382, 2)\n",
      "   playlist_id  title\n",
      "0       644838  12727\n",
      "0      3120683    183\n",
      "0      4278112  12389\n",
      "1      4278112  18698\n",
      "2      4278112  18925\n",
      "3      4278112  11695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "def get_playlist_titles(playlist_final):\n",
    "    playlist_tags_list = str_tags_to_list(playlist_final['title'])\n",
    "    return [[playlist_final['playlist_id'], playlist_tag] for playlist_tag in playlist_tags_list]\n",
    "\n",
    "try:\n",
    "    playlist_titles = pd.DataFrame.from_csv('../datasets/titles.csv')\n",
    "except:\n",
    "    playlist_titles = pd.concat([pd.DataFrame(data=get_playlist_titles(playlist_final), columns=['playlist_id', 'title']) for index, playlist_final in playlists_final.iterrows()])\n",
    "    playlist_titles.to_csv('../datasets/titles.csv')\n",
    "\n",
    "print('playlist_titles {}'.format(playlist_titles.shape))\n",
    "print(playlist_titles.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_owner (57561, 2)\n",
      "   playlist_id  owner\n",
      "0       644838  41504\n",
      "1      7577564  41504\n",
      "2      3120683  44542\n",
      "3      4278112  44542\n",
      "4      8656823  44542\n",
      "5     10961458  44542\n"
     ]
    }
   ],
   "source": [
    "playlist_owner = pd.DataFrame()\n",
    "playlist_owner['playlist_id'] = playlists_final['playlist_id']\n",
    "playlist_owner['owner'] = playlists_final['owner']\n",
    "print('playlist_owner {}'.format(playlist_owner.shape))\n",
    "print(playlist_owner.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "Tracks with tags count: 97211\n",
      "Unique tags count: 31900\n",
      "\n",
      "Tracks with album count: 73244\n",
      "Unique album count: 27604\n",
      "\n",
      "Tracks with artists count: 100000\n",
      "Unique artists count: 17536\n",
      "\n",
      "Playlists with title count: 52384\n",
      "Unique titles count: 21064\n",
      "\n",
      "Playlist with owner count: 57561\n",
      "Unique owner count: 15264\n",
      "\n",
      "Unique tracks count: 100000\n",
      "Unique playlist count: 57561\n",
      "Target tracks count: 32195\n",
      "Target playlists count: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Data info:')\n",
    "print('Tracks with tags count: {}'.format(tracks_tags['track_id'].nunique()))\n",
    "print('Unique tags count: {}\\n'.format(tracks_tags['tag'].nunique()))\n",
    "\n",
    "print('Tracks with album count: {}'.format(tracks_albums['track_id'].nunique()))\n",
    "print('Unique album count: {}\\n'.format(tracks_albums['album'].nunique()))\n",
    "\n",
    "print('Tracks with artists count: {}'.format(tracks_artist['track_id'].nunique()))\n",
    "print('Unique artists count: {}\\n'.format(tracks_artist['artist_id'].nunique()))\n",
    "\n",
    "print('Playlists with title count: {}'.format(playlist_titles['playlist_id'].nunique()))\n",
    "print('Unique titles count: {}\\n'.format(playlist_titles['title'].nunique()))\n",
    "\n",
    "print('Playlist with owner count: {}'.format(playlist_owner['playlist_id'].nunique()))\n",
    "print('Unique owner count: {}\\n'.format(playlist_owner['owner'].nunique()))\n",
    "\n",
    "print('Unique tracks count: {}'.format(tracks_final['track_id'].nunique()))\n",
    "print('Unique playlist count: {}'.format(playlists_final['playlist_id'].nunique()))\n",
    "print('Target tracks count: {}'.format(target_tracks['track_id'].nunique()))\n",
    "print('Target playlists count: {}'.format(target_playlists['playlist_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id_le classes: 100000\n",
      "playlist_id_le classes: 57561\n",
      "title_le classes: 21064\n",
      "owner_le classes: 15264\n",
      "tags_le classes: 31900\n",
      "album_le classes: 27604\n",
      "artist_le classes: 17536\n"
     ]
    }
   ],
   "source": [
    "track_id_le = preprocessing.LabelEncoder()\n",
    "track_id_le.fit(list(tracks_final['track_id']))\n",
    "print('track_id_le classes: {}'.format(len(track_id_le.classes_)))\n",
    "\n",
    "playlist_id_le = preprocessing.LabelEncoder()\n",
    "playlist_id_le.fit(list(playlists_final['playlist_id']))\n",
    "print('playlist_id_le classes: {}'.format(len(playlist_id_le.classes_)))\n",
    "\n",
    "title_le = preprocessing.LabelEncoder()\n",
    "title_le.fit(list(playlist_titles['title']))\n",
    "print('title_le classes: {}'.format(len(title_le.classes_)))\n",
    "\n",
    "owner_le = preprocessing.LabelEncoder()\n",
    "owner_le.fit(list(playlist_owner['owner']))\n",
    "print('owner_le classes: {}'.format(len(owner_le.classes_)))\n",
    "\n",
    "tags_le = preprocessing.LabelEncoder()\n",
    "tags_le.fit(list(tracks_tags['tag']))\n",
    "print('tags_le classes: {}'.format(len(tags_le.classes_)))\n",
    "\n",
    "album_le = preprocessing.LabelEncoder()\n",
    "album_le.fit(list(tracks_albums['album']))\n",
    "print('album_le classes: {}'.format(len(album_le.classes_)))\n",
    "\n",
    "artist_le = preprocessing.LabelEncoder()\n",
    "artist_le.fit(list(tracks_artist['artist_id']))\n",
    "print('artist_le classes: {}'.format(len(artist_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_playlists_and_tracks (362661, 2)\n",
      "   playlist_id  track_id\n",
      "0     10024884   2879006\n",
      "1     10024884   1532328\n",
      "2     10024884   3027673\n",
      "3     10024884   3236144\n",
      "4     10024884   1563134\n",
      "5     10024884    435345\n",
      "6     10024884    353291\n",
      "7     10024884    247331\n",
      "8     10024884    161455\n",
      "9     10024884   3338954\n"
     ]
    }
   ],
   "source": [
    "# Playlist and tracks that belong to them\n",
    "target_playlists_and_tracks = pd.merge(target_playlists, train_final, on='playlist_id')\n",
    "print('target_playlists_and_tracks {}'.format(target_playlists_and_tracks.shape))\n",
    "print(target_playlists_and_tracks.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_final: (1040522, 4)\n",
      "   playlist_id  track_id  transformed_track_id  transformed_playlist_id\n",
      "0      3271849   2801526                 71058                     8890\n",
      "1      5616275    727878                 19741                    22426\n",
      "2     11267488   2805283                 71298                    54743\n",
      "3     10103900   1515105                 36851                    46970\n",
      "4      3836898   2945623                 76310                    11967\n",
      "training_set: (1010522, 4)\n",
      "   playlist_id  track_id  transformed_track_id  transformed_playlist_id\n",
      "0      3271849   2801526                 71058                     8890\n",
      "1      5616275    727878                 19741                    22426\n",
      "2     11267488   2805283                 71298                    54743\n",
      "3     10103900   1515105                 36851                    46970\n",
      "4      3836898   2945623                 76310                    11967\n",
      "validation_set: (30000, 2)\n",
      "   playlist_id  track_id\n",
      "0         7614   1609224\n",
      "1         7614   1614974\n",
      "2         7614   3711434\n",
      "3         7692   1232748\n",
      "4         7692     88210\n",
      "test_target_tracks: (21929, 2)\n",
      "   track_id  transformed_track_id\n",
      "0   1609224                 39285\n",
      "1   1614974                 39451\n",
      "2   3711434                 94876\n",
      "3   1232748                 30527\n",
      "4     88210                  1566\n"
     ]
    }
   ],
   "source": [
    "def split_training_data(train_final, target_playlists_and_tracks, random_state):\n",
    "    validation_set = target_playlists_and_tracks.groupby(['playlist_id'])\\\n",
    "                        .apply(lambda x: x.sample(n=3, random_state=random_state))\\\n",
    "                        .reset_index(drop=True)\n",
    "    df_concat = pd.concat([train_final, validation_set])\n",
    "    training_set = df_concat.drop_duplicates(keep=False)\n",
    "    return training_set, validation_set\n",
    "\n",
    "# Split dataset - from all target playlists remove randomly 3 tracks\n",
    "training_set, validation_set = split_training_data(train_final, target_playlists_and_tracks, random_state=5)\n",
    "test_target_tracks = validation_set['track_id'].drop_duplicates(keep='first').to_frame()\n",
    "test_target_tracks['transformed_track_id'] = track_id_le.transform(list(test_target_tracks['track_id']))\n",
    "target_tracks['transformed_track_id'] = track_id_le.transform(list(target_tracks['track_id']))\n",
    "\n",
    "training_set['transformed_track_id'] = track_id_le.transform(list(training_set['track_id']))\n",
    "training_set['transformed_playlist_id'] = playlist_id_le.transform(list(training_set['playlist_id']))\n",
    "target_playlists['transformed_playlist_id'] = playlist_id_le.transform(list(target_playlists['playlist_id']))\n",
    "\n",
    "train_final['transformed_track_id'] = track_id_le.transform(list(train_final['track_id']))\n",
    "train_final['transformed_playlist_id'] = playlist_id_le.transform(list(train_final['playlist_id']))\n",
    "\n",
    "print('train_final: {}'.format(train_final.shape))\n",
    "print(train_final.head(5))\n",
    "print('training_set: {}'.format(training_set.shape))\n",
    "print(training_set.head(5))\n",
    "print('validation_set: {}'.format(validation_set.shape))\n",
    "print(validation_set.head(5))\n",
    "print('test_target_tracks: {}'.format(test_target_tracks.shape))\n",
    "print(test_target_tracks.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_titles\n",
      "   playlist_id  title  transformed_playlist_id  transformed_title_id\n",
      "0       644838  12727                     2514                112727\n",
      "0      3120683    183                     7829                100183\n",
      "0      4278112  12389                    14708                112389\n",
      "1      4278112  18698                    14708                118698\n",
      "playlist_owner\n",
      "   playlist_id  owner  transformed_playlist_id  transformed_owner\n",
      "0       644838  41504                     2514             132679\n",
      "1      7577564  41504                    35844             132679\n",
      "2      3120683  44542                     7829             135702\n",
      "3      4278112  44542                    14708             135702\n",
      "tracks_tags\n",
      "   track_id    tag  weight  transformed_track_id  transformed_tag\n",
      "0   2972914  54087     2.5                 77187             6683\n",
      "1   2972914   1757     2.0                 77187              257\n",
      "2   2972914   1718     1.6                 77187              254\n",
      "tracks_albums\n",
      "   track_id  album  transformed_track_id  transformed_album\n",
      "0   2972914      7                 77187              31901\n",
      "0   2750239      8                 69189              31902\n",
      "0   1550729      9                 37833              31903\n",
      "tracks_artist\n",
      "   track_id  artist_id  transformed_track_id  transformed_artist_id\n",
      "0   2972914        144                 77187                  59506\n",
      "1   2750239        246                 69189                  59508\n",
      "2   1550729        144                 37833                  59506\n"
     ]
    }
   ],
   "source": [
    "unique_tracks_count = tracks_final['track_id'].nunique()\n",
    "\n",
    "playlist_titles['transformed_playlist_id'] = playlist_id_le.transform(list(playlist_titles['playlist_id']))\n",
    "playlist_titles['transformed_title_id'] = list(map(lambda x: x + unique_tracks_count,\\\n",
    "                                                   title_le.transform(list(playlist_titles['title']))))\n",
    "print('playlist_titles')\n",
    "print(playlist_titles.head(4))\n",
    "\n",
    "playlist_owner['transformed_playlist_id'] = playlist_id_le.transform(list(playlist_owner['playlist_id']))\n",
    "playlist_owner['transformed_owner'] = list(map(lambda x: x + unique_tracks_count + len(title_le.classes_),\\\n",
    "                                                   owner_le.transform(list(playlist_owner['owner']))))\n",
    "print('playlist_owner')\n",
    "print(playlist_owner.head(4))\n",
    "\n",
    "tracks_tags['transformed_track_id'] = track_id_le.transform(list(tracks_tags['track_id']))\n",
    "tracks_tags['transformed_tag'] = tags_le.transform(list(tracks_tags['tag']))\n",
    "print('tracks_tags')\n",
    "print(tracks_tags.head(3))\n",
    "\n",
    "tracks_albums['transformed_track_id'] = track_id_le.transform(list(tracks_albums['track_id']))\n",
    "tracks_albums['transformed_album'] = list(map(lambda x: x + len(tags_le.classes_),\\\n",
    "                                  album_le.transform(list(tracks_albums['album']))))\n",
    "print('tracks_albums')\n",
    "print(tracks_albums.head(3))\n",
    "\n",
    "tracks_artist['transformed_track_id'] = track_id_le.transform(list(tracks_artist['track_id']))\n",
    "tracks_artist['transformed_artist_id'] = list(map(lambda x: x + len(tags_le.classes_) + len(album_le.classes_),\\\n",
    "                                                  artist_le.transform(list(tracks_artist['artist_id']))))\n",
    "print('tracks_artist')\n",
    "print(tracks_artist.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SUBMISSION:\n",
    "    print(training_set.shape)\n",
    "    training_set = train_final\n",
    "    print(training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urm_with_title_ones shape: (1118904,), vector: [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "urm_with_all_ones shape: (1176465,), vector: [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "(57561, 136328)\n",
      "tracks_per_playlist.shape (57561, 136328)\n",
      "playlist_per_track.shape (57561, 136328)\n"
     ]
    }
   ],
   "source": [
    "urm_with_title_ones = np.ones(training_set.shape[0] + playlist_titles.shape[0])\n",
    "urm_with_all_ones = np.ones(training_set.shape[0] + playlist_titles.shape[0] + playlist_owner.shape[0])\n",
    "\n",
    "print('urm_with_title_ones shape: {}, vector: {}'.format(urm_with_title_ones.shape, urm_with_title_ones))\n",
    "print('urm_with_all_ones shape: {}, vector: {}'.format(urm_with_all_ones.shape, urm_with_all_ones))\n",
    "\n",
    "URM_with_title = scipy.sparse.coo_matrix((urm_with_title_ones, (list(training_set['transformed_playlist_id']) + list(playlist_titles['transformed_playlist_id']),\n",
    "                                                                list(training_set['transformed_track_id']) + list(playlist_titles['transformed_title_id']))))\n",
    "\n",
    "URM_with_all = scipy.sparse.coo_matrix((urm_with_all_ones, (list(training_set['transformed_playlist_id']) + list(playlist_titles['transformed_playlist_id']) + list(playlist_owner['transformed_playlist_id']),\n",
    "                                                            list(training_set['transformed_track_id']) + list(playlist_titles['transformed_title_id']) + list(playlist_owner['transformed_owner']))))\n",
    "\n",
    "URM_with_title = URM_with_title.tocsr()\n",
    "URM_with_all = URM_with_all.tocsr()\n",
    "\n",
    "print(URM_with_all.shape)\n",
    "tracks_per_playlist = (URM_with_all > 0).sum(axis=1)\n",
    "playlist_per_track = (URM_with_all > 0).sum(axis=0)\n",
    "\n",
    "print('tracks_per_playlist.shape {}'.format(URM_with_all.shape))\n",
    "print('playlist_per_track.shape {}'.format(URM_with_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urm_ones shape: (1010522,), vector: [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "(100000, 57561)\n"
     ]
    }
   ],
   "source": [
    "urm_ones = np.ones(training_set.shape[0])\n",
    "print('urm_ones shape: {}, vector: {}'.format(urm_ones.shape, urm_ones))\n",
    "\n",
    "URM = scipy.sparse.coo_matrix((urm_ones, (list(training_set['transformed_track_id']),\n",
    "                                          list(training_set['transformed_playlist_id']))))\n",
    "print(URM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_tags.shape (483501, 5)\n",
      "tracks_albums.shape (73244, 4)\n",
      "tracks_artist.shape (100000, 4)\n",
      "values shape: (656745,), vector: [ 2.5  2.   1.6 ...,  1.   1.   1. ]\n",
      "(100000, 77040)\n",
      "features_per_item.shape (100000, 1)\n",
      "items_per_feature.shape (1, 77040)\n"
     ]
    }
   ],
   "source": [
    "print('tracks_tags.shape {}'.format(tracks_tags.shape))\n",
    "print('tracks_albums.shape {}'.format(tracks_albums.shape))\n",
    "print('tracks_artist.shape {}'.format(tracks_artist.shape))\n",
    "\n",
    "tracks_albums_ones = np.ones(tracks_albums.shape[0])\n",
    "tracks_artist_ones = np.ones(tracks_artist.shape[0])\n",
    "values = np.append(tracks_tags['weight'], np.append(tracks_albums_ones, tracks_artist_ones))\n",
    "print('values shape: {}, vector: {}'.format(values.shape, values))\n",
    "\n",
    "ICM = scipy.sparse.coo_matrix((values, (list(tracks_tags['transformed_track_id']) + list(tracks_albums['transformed_track_id']) + list(tracks_artist['transformed_track_id']),\\\n",
    "                                        list(tracks_tags['transformed_tag']) + list(tracks_albums['transformed_album']) + list(tracks_artist['transformed_artist_id']))))\n",
    "\n",
    "print(ICM.shape)\n",
    "features_per_item = (ICM > 0).sum(axis=1)\n",
    "items_per_feature = (ICM > 0).sum(axis=0)\n",
    "\n",
    "print('features_per_item.shape {}'.format(features_per_item.shape))\n",
    "print('items_per_feature.shape {}'.format(items_per_feature.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        \n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        print(\"Computing distance\")\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "\n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "#         co_counts = co_counts - scipy.sparse.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computing distance\n",
      "Computed\n",
      "Applied shrinkage\n"
     ]
    }
   ],
   "source": [
    "distance = Cosine(shrinkage=8)\n",
    "playlist_similarity_title = distance.compute(URM_with_title.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computing distance\n",
      "Computed\n",
      "Applied shrinkage\n"
     ]
    }
   ],
   "source": [
    "distance = Cosine(shrinkage=8)\n",
    "playlist_similarity_all = distance.compute(URM_with_all.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computing distance\n",
      "Computed\n"
     ]
    }
   ],
   "source": [
    "distance = Cosine(shrinkage=0)\n",
    "items_similarity_ICM = distance.compute(ICM.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computing distance\n",
      "Computed\n",
      "Applied shrinkage\n"
     ]
    }
   ],
   "source": [
    "distance = Cosine(shrinkage=0.1)\n",
    "items_similarity_URM = distance.compute(URM.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/core/series.py:2849: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  infer_datetime_format=infer_datetime_format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026331008021518693 0.04821255959483566 0.031002219568091925 0.032309362264514654\n"
     ]
    }
   ],
   "source": [
    "item_scores = pd.Series.from_csv('./hybrid_weights/item_scores.csv')\n",
    "content_scores = pd.Series.from_csv('./hybrid_weights/content_scores.csv')\n",
    "\n",
    "user_with_all_scores = pd.Series.from_csv('./hybrid_weights/user_with_all.csv')\n",
    "user_with_title_scores = pd.Series.from_csv('./hybrid_weights/user_with_title.csv')\n",
    "\n",
    "mean_i_mAP = item_scores.mean()\n",
    "mean_c_mAP = content_scores.mean()\n",
    "\n",
    "mean_uto_mAP = user_with_all_scores.mean()\n",
    "mean_ut_mAP = user_with_title_scores.mean()\n",
    "\n",
    "print('{} {} {} {}'.format(mean_i_mAP, mean_c_mAP, mean_ut_mAP, mean_uto_mAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_playlists_and_tracks (332661, 10)\n",
      "   playlist_id  transformed_playlist_id_x  track_id  transformed_track_id  \\\n",
      "0     10024884                      46297   2879006                 74168   \n",
      "1     10024884                      46297   1532328                 37429   \n",
      "2      8466002                      41478   1532328                 37429   \n",
      "3        68290                        550   1532328                 37429   \n",
      "4      3520148                      10188   1532328                 37429   \n",
      "\n",
      "   transformed_playlist_id_y  artist_id  duration  playcount     album  \\\n",
      "0                      46297     337976    185000       14.0  [155542]   \n",
      "1                      46297      43620    271000       37.0   [21332]   \n",
      "2                      41478      43620    271000       37.0   [21332]   \n",
      "3                        550      43620    271000       37.0   [21332]   \n",
      "4                      10188      43620    271000       37.0   [21332]   \n",
      "\n",
      "                                     tags  \n",
      "0   [35233, 196918, 35060, 115355, 35129]  \n",
      "1  [115355, 115684, 11056, 25437, 189631]  \n",
      "2  [115355, 115684, 11056, 25437, 189631]  \n",
      "3  [115355, 115684, 11056, 25437, 189631]  \n",
      "4  [115355, 115684, 11056, 25437, 189631]  \n"
     ]
    }
   ],
   "source": [
    "target_playlists_and_tracks = pd.merge(target_playlists, training_set, on='playlist_id')\n",
    "target_playlists_and_tracks = pd.merge(target_playlists_and_tracks, tracks_final, on='track_id')\n",
    "print('target_playlists_and_tracks {}'.format(target_playlists_and_tracks.shape))\n",
    "print(target_playlists_and_tracks.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   playlist_id  transformed_playlist_id  item_mAP  content_mAP  user_all_mAP  \\\n",
      "0    6264193.0                  26637.0  0.308117     0.301665      0.303278   \n",
      "1   10794082.0                  51986.0  0.298440     0.281773      0.284366   \n",
      "2    5895355.0                  24318.0  0.259091     0.298440      0.283684   \n",
      "\n",
      "   user_title_mAP   sum_mAP  created_at  numtracks  duration  known_numtracks  \n",
      "0        0.301397  0.911179  1274730103         61     13311                4  \n",
      "1        0.285190  0.865403  1219268098         14      4297                2  \n",
      "2        0.287189  0.844719  1227053150         16      3249                2  \n"
     ]
    }
   ],
   "source": [
    "target_playlists['item_mAP'] = item_scores\n",
    "target_playlists['content_mAP'] = content_scores\n",
    "target_playlists['user_all_mAP'] = user_with_all_scores\n",
    "target_playlists['user_title_mAP'] = user_with_title_scores\n",
    "\n",
    "def sum_mAP(playlist):\n",
    "    playlist['sum_mAP'] = playlist['item_mAP'] + playlist['user_title_mAP'] + playlist['content_mAP']\n",
    "    return playlist\n",
    "\n",
    "target_playlists = target_playlists.apply(lambda playlist: sum_mAP(playlist), axis=1)\n",
    "target_playlists = target_playlists.sort_values(['sum_mAP'], ascending=False)\n",
    "target_playlists_and_data = pd.merge(target_playlists, playlists_final, on='playlist_id')\n",
    "target_playlists_and_data = target_playlists_and_data.drop('owner', 1)\n",
    "target_playlists_and_data = target_playlists_and_data.drop('title', 1)\n",
    "\n",
    "def known_numtracks(playlist):\n",
    "    playlist['known_numtracks'] = len(target_playlists_and_tracks.loc[target_playlists_and_tracks['playlist_id'] == playlist['playlist_id']])\n",
    "    return playlist\n",
    "\n",
    "target_playlists_and_data = target_playlists_and_data.apply(lambda playlist: known_numtracks(playlist), axis=1)\n",
    "print(target_playlists_and_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       track_id  transformed_track_id  artist_id  duration  playcount album  \\\n",
      "25226   2209516                 55057     319839        -1      711.0    []   \n",
      "1272    1187609                 28910      48894        -1      249.0    []   \n",
      "1271    1507255                 36711     230462        -1      115.0    []   \n",
      "5364     906185                 22939     168149        -1     4993.0    []   \n",
      "11817    451847                 11899     268875        -1      632.0    []   \n",
      "5375    2610563                 65506     168149        -1     1731.0    []   \n",
      "1248    1758377                 43354     312689        -1        4.0    []   \n",
      "1273     945403                 23711     406890        -1        0.0    []   \n",
      "18765   3216726                 83496     206962        -1       21.0    []   \n",
      "5417      23086                   456     392005        -1       14.0    []   \n",
      "\n",
      "      tags  \n",
      "25226   []  \n",
      "1272    []  \n",
      "1271    []  \n",
      "5364    []  \n",
      "11817   []  \n",
      "5375    []  \n",
      "1248    []  \n",
      "1273    []  \n",
      "18765   []  \n",
      "5417    []  \n"
     ]
    }
   ],
   "source": [
    "target_tracks_and_data = pd.merge(target_tracks, tracks_final, on='track_id')\n",
    "target_tracks_and_data = target_tracks_and_data.sort_values(by=['duration'])\n",
    "print(target_tracks_and_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_subsets(elems, length, expected_sum):\n",
    "    response = []\n",
    "\n",
    "    def find_all_subsets_rec(available_elems, acc_set):\n",
    "        cur_sum = sum([x[0] for x in acc_set])\n",
    "\n",
    "        if cur_sum > expected_sum:\n",
    "            return\n",
    "        if length == len(acc_set):\n",
    "            if cur_sum == expected_sum:\n",
    "                response.append(acc_set)\n",
    "            return\n",
    "        if len(available_elems) + len(acc_set) < length:\n",
    "            return\n",
    "\n",
    "        find_all_subsets_rec(available_elems[1:], acc_set + [available_elems[0]])\n",
    "        find_all_subsets_rec(available_elems[1:], acc_set)\n",
    "\n",
    "    find_all_subsets_rec(elems, [])\n",
    "    response_with_scores = [(r, sum([x[2] for x in r])) for r in response]\n",
    "    return list(sorted(response_with_scores, key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, k, to_predict=3):\n",
    "        self.k = k\n",
    "        self.to_predict = to_predict\n",
    "    \n",
    "    def fit(self, training_set, target_tracks, playlist_similarity_all, playlist_similarity_title, URM, items_similarity_ICM, items_similarity_URM):\n",
    "        self.training_set = training_set\n",
    "        self.playlist_similarity_all = playlist_similarity_all\n",
    "        self.playlist_similarity_title = playlist_similarity_title\n",
    "        self.items_similarity_ICM = items_similarity_ICM\n",
    "        self.items_similarity_URM = items_similarity_URM\n",
    "        self.URM = check_matrix(URM, 'csc', dtype=np.float32)\n",
    "        self.target_tracks_mask = np.zeros(self.items_similarity_ICM.shape[0])\n",
    "        for value in list(target_tracks['transformed_track_id']):\n",
    "            self.target_tracks_mask[value] = 1\n",
    "    \n",
    "    def recommend(self, target_playlists):\n",
    "        def make_recommendation(playlist):\n",
    "            tracks_on_playlist = self.training_set.loc[self.training_set['playlist_id'] == playlist['playlist_id']]\n",
    "            transformed_tracks_on_playlist = track_id_le.transform(list(tracks_on_playlist['track_id']))\n",
    "            tracks_on_playlist_mask = np.ones(self.items_similarity_ICM.shape[0])\n",
    "            for value in transformed_tracks_on_playlist:\n",
    "                tracks_on_playlist_mask[value] = 0\n",
    "   \n",
    "            # ContentBased similarity\n",
    "            reg = 10e-2\n",
    "            c_mAP = playlist['content_mAP'] + reg * mean_c_mAP\n",
    "            ut_mAP = playlist['user_title_mAP'] + reg * mean_ut_mAP\n",
    "            uto_mAP = playlist['user_all_mAP'] + reg * mean_uto_mAP\n",
    "            i_mAP = playlist['item_mAP'] + reg * mean_i_mAP\n",
    "          \n",
    "            # Content similarity\n",
    "            correlation_content = np.squeeze(np.asarray(self.items_similarity_ICM[:, transformed_tracks_on_playlist].mean(axis=1)))            \n",
    "            correlation_content = correlation_content / max(correlation_content)\n",
    "\n",
    "            # ItemBased similarity\n",
    "            correlation_item = np.squeeze(np.asarray(self.items_similarity_URM[:, transformed_tracks_on_playlist].mean(axis=1)))\n",
    "            correlation_item = correlation_item / max(correlation_item)\n",
    "            \n",
    "            # UserBased similarity\n",
    "            if playlist['user_title_mAP'] > playlist['user_all_mAP'] * 1.1:\n",
    "                uu_mAP = ut_mAP\n",
    "                similar_playlists = np.squeeze(self.playlist_similarity_title.getcol(playlist['transformed_playlist_id']).toarray())\n",
    "            else:\n",
    "                uu_mAP = uto_mAP\n",
    "                similar_playlists = np.squeeze(self.playlist_similarity_all.getcol(playlist['transformed_playlist_id']).toarray())\n",
    "\n",
    "            indices = np.argpartition(similar_playlists, -self.k)[-self.k:]\n",
    "            ub_scores = np.take(similar_playlists, indices)\n",
    "            correlation_user = np.zeros(self.URM.shape[0])\n",
    "            for index, score in zip(indices, ub_scores):\n",
    "                correlation_user += np.squeeze(self.URM.getcol(index).toarray()) * score\n",
    "            correlation_user = correlation_user / max(correlation_user)     \n",
    "            \n",
    "            correlation = correlation_content * c_mAP + correlation_item * i_mAP + correlation_user * uu_mAP\n",
    "            correlation = correlation * self.target_tracks_mask\n",
    "            correlation = correlation * tracks_on_playlist_mask\n",
    "            \n",
    "#             ind = np.argpartition(list(correlation), -self.to_predict)[-self.to_predict:]\n",
    "            ind = np.argpartition(list(correlation), -7)[-7:]\n",
    "            scores = np.take(correlation, ind)\n",
    "            \n",
    "            ind, scores = zip(*sorted(zip(ind, scores), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "            flag = True\n",
    "            d = {'transformed_track_id': ind, 'score': scores}\n",
    "            df = pd.DataFrame(data=d)\n",
    "            df = pd.merge(df, target_tracks_and_data, on='transformed_track_id')\n",
    "            tracks_on_playlist = target_playlists_and_tracks.loc[target_playlists_and_tracks['playlist_id'] == playlist['playlist_id']]\n",
    "            \n",
    "            if (playlist['numtracks'] - len(tracks_on_playlist) == 5):\n",
    "                total_duration = playlist['duration']\n",
    "                known_duration = tracks_on_playlist['duration'].sum() / 1000\n",
    "                expected_duration = (total_duration - known_duration) * 1000\n",
    "# # #                 expected_duration = validation_set_data.loc[validation_set_data['playlist_id'] == playlist['playlist_id']]['duration'].sum()\n",
    "                \n",
    "                isd = list(zip(df['duration'], df['track_id'], df['score']))\n",
    "                subsets = find_all_subsets(elems=isd, length=5, expected_sum=expected_duration)\n",
    "\n",
    "                if len(subsets) > 0:\n",
    "                    best = subsets[0][0]\n",
    "                    recommended_tracks = [best[0][1], best[1][1], best[2][1], best[3][1], best[4][1]]\n",
    "                    scores = [best[0][2], best[1][2], best[2][2], best[3][2], best[4][2]]\n",
    "                    flag = False\n",
    "\n",
    "#             recommended_tracks = track_id_le.inverse_transform(ind)\n",
    "            if flag:\n",
    "                recommended_tracks = track_id_le.inverse_transform(ind[:5])\n",
    "                scores = scores[:5]\n",
    "            playlist['recommendation'] = list(recommended_tracks)\n",
    "            playlist['scores'] = list(scores)\n",
    "            return playlist\n",
    "\n",
    "        recommended_items = target_playlists.apply(lambda playlist: make_recommendation(playlist), axis=1)\n",
    "        return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Took 0.11622s\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "begin = time.time()\n",
    "recommender = HybridRecommender(k=15, to_predict=3)\n",
    "# recommender.fit(training_set, test_target_tracks, playlist_similarity_all, playlist_similarity_title, URM, items_similarity_ICM, items_similarity_URM)\n",
    "recommender.fit(training_set, target_tracks, playlist_similarity_all, playlist_similarity_title, URM, items_similarity_ICM, items_similarity_URM)\n",
    "print('Took {0:.{digits}f}s'.format(time.time() - begin, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending...\n",
      "Took 18.71687s\n",
      "recommended_items (100, 13)\n",
      "    playlist_id  transformed_playlist_id  item_mAP  content_mAP  user_all_mAP  \\\n",
      "0     6264193.0                  26637.0  0.308117     0.301665      0.303278   \n",
      "1    10794082.0                  51986.0  0.298440     0.281773      0.284366   \n",
      "2     5895355.0                  24318.0  0.259091     0.298440      0.283684   \n",
      "3     5378504.0                  20851.0  0.282056     0.271343      0.283830   \n",
      "4     6985944.0                  31100.0  0.252660     0.305429      0.272011   \n",
      "5     7222096.0                  32566.0  0.256645     0.306504      0.267199   \n",
      "6    10315407.0                  48780.0  0.279461     0.253440      0.290015   \n",
      "7     3140454.0                   7980.0  0.265824     0.282364      0.231248   \n",
      "8     7270644.0                  32821.0  0.258531     0.285905      0.268235   \n",
      "9     8419128.0                  41154.0  0.252741     0.281235      0.253171   \n",
      "10    6299114.0                  26865.0  0.257207     0.249444      0.281450   \n",
      "11    4711978.0                  16954.0  0.269891     0.272472      0.237633   \n",
      "12    4091447.0                  13533.0  0.263335     0.263731      0.258216   \n",
      "13    7939222.0                  38261.0  0.272258     0.214423      0.289569   \n",
      "14    5396367.0                  20961.0  0.275913     0.279784      0.227383   \n",
      "15   11015974.0                  53514.0  0.258818     0.252096      0.262257   \n",
      "16   10440335.0                  49661.0  0.259257     0.231623      0.274418   \n",
      "17   11386921.0                  55278.0  0.246756     0.247016      0.268171   \n",
      "18    7385365.0                  33510.0  0.256658     0.271174      0.232675   \n",
      "19    3193281.0                   8344.0  0.253708     0.238117      0.266934   \n",
      "\n",
      "    user_title_mAP   sum_mAP    created_at  numtracks  duration  \\\n",
      "0         0.301397  0.911179  1.274730e+09       61.0   13311.0   \n",
      "1         0.285190  0.865403  1.219268e+09       14.0    4297.0   \n",
      "2         0.287189  0.844719  1.227053e+09       16.0    3249.0   \n",
      "3         0.283830  0.837229  1.275815e+09       50.0   12356.0   \n",
      "4         0.272549  0.830638  1.226194e+09       21.0    4218.0   \n",
      "5         0.266124  0.829273  1.233438e+09       31.0    6837.0   \n",
      "6         0.286520  0.819421  1.336568e+09       18.0    5040.0   \n",
      "7         0.269569  0.817757  1.313666e+09       10.0   11918.0   \n",
      "8         0.269311  0.813747  1.238383e+09       69.0   20088.0   \n",
      "9         0.253171  0.787147  1.213031e+09       28.0    9235.0   \n",
      "10        0.280375  0.787026  1.268254e+09       16.0    3477.0   \n",
      "11        0.244192  0.786555  1.263246e+09       11.0    1985.0   \n",
      "12        0.258216  0.785283  1.285898e+09       24.0    4825.0   \n",
      "13        0.287687  0.774368  1.290615e+09       14.0    4450.0   \n",
      "14        0.214018  0.769715  1.319637e+09       49.0   18743.0   \n",
      "15        0.254954  0.765868  1.214567e+09       23.0    1959.0   \n",
      "16        0.274418  0.765298  1.244301e+09       15.0    8255.0   \n",
      "17        0.268171  0.761943  1.309795e+09       16.0    3865.0   \n",
      "18        0.233482  0.761313  1.266864e+09       13.0    3139.0   \n",
      "19        0.268816  0.760641  1.416466e+09       10.0    2338.0   \n",
      "\n",
      "    known_numtracks                                 recommendation  \\\n",
      "0               4.0  [2213769, 2279586, 1155144, 1193555, 3194355]   \n",
      "1               2.0   [2962335, 2130160, 1525529, 516549, 1150479]   \n",
      "2               2.0   [2864733, 2664554, 2888848, 324667, 2680074]   \n",
      "3              38.0    [687284, 287188, 1400614, 1466937, 1251925]   \n",
      "4               8.0   [1726518, 1832673, 2894730, 2752761, 968843]   \n",
      "5              14.0    [89072, 1770805, 3769277, 2591565, 1210877]   \n",
      "6               3.0   [177433, 3650180, 2674331, 2791782, 2328432]   \n",
      "7               2.0  [3828279, 1038829, 1549315, 1355400, 1818948]   \n",
      "8              16.0  [1475740, 1255643, 3227178, 2875667, 1671246]   \n",
      "9               7.0  [1466722, 1293904, 2709687, 2974784, 1832475]   \n",
      "10              3.0  [1493798, 1506087, 1291630, 2337372, 2602353]   \n",
      "11              3.0   [2731014, 2638738, 290254, 2173235, 1741901]   \n",
      "12             14.0     [255023, 3027818, 69617, 1758377, 2571208]   \n",
      "13              3.0  [1724112, 1711859, 3632056, 2253243, 3128635]   \n",
      "14             31.0   [1406613, 1824880, 3735174, 356786, 2810325]   \n",
      "15              9.0  [2787661, 3228997, 1942757, 1805611, 3747659]   \n",
      "16              4.0   [1373949, 723444, 3004917, 2134886, 2638201]   \n",
      "17              7.0     [494198, 1057075, 12344, 2898312, 2762482]   \n",
      "18              4.0     [233723, 2881435, 491108, 626264, 3569431]   \n",
      "19              2.0   [2293396, 946533, 2003973, 2874676, 1202169]   \n",
      "\n",
      "                                               scores  \n",
      "0   [0.447212329165, 0.421470930831, 0.40678246881...  \n",
      "1   [0.358014614638, 0.307329383564, 0.25017311156...  \n",
      "2   [0.237897866372, 0.234567080559, 0.22712631477...  \n",
      "3   [0.301491455341, 0.296428218285, 0.27304020493...  \n",
      "4   [0.446896891215, 0.426273443469, 0.40299954536...  \n",
      "5   [0.53581132568, 0.268638315278, 0.251206939231...  \n",
      "6   [0.422142100768, 0.346344761794, 0.32982527633...  \n",
      "7   [0.482225994877, 0.458585595168, 0.45395015122...  \n",
      "8   [0.334302272182, 0.248513057465, 0.18826851699...  \n",
      "9   [0.454960969518, 0.442500564704, 0.44181479840...  \n",
      "10  [0.402906970712, 0.299194520347, 0.29140140066...  \n",
      "11  [0.424939275246, 0.420736295506, 0.40856568852...  \n",
      "12  [0.191813356444, 0.140816483507, 0.13830837697...  \n",
      "13  [0.232226145305, 0.210971675351, 0.09500851563...  \n",
      "14  [0.319670156977, 0.289940754992, 0.24333855349...  \n",
      "15  [0.383831276324, 0.36987241986, 0.347622125973...  \n",
      "16  [0.277342188225, 0.233839814041, 0.20874325719...  \n",
      "17  [0.373417245446, 0.358706330914, 0.35185248904...  \n",
      "18  [0.470585033465, 0.463114939643, 0.45543370683...  \n",
      "19  [0.451965038052, 0.430745800504, 0.41024610328...  \n"
     ]
    }
   ],
   "source": [
    "print('Recommending...')\n",
    "begin = time.time()\n",
    "recommended_items = recommender.recommend(target_playlists_and_data.head(100))\n",
    "\n",
    "print('Took {0:.{digits}f}s'.format(time.time() - begin, digits=5))\n",
    "\n",
    "print('recommended_items {}'.format(recommended_items.shape))\n",
    "print(recommended_items.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Precision: 0.20800, mAP: 0.23010, took 0.74911s\n"
     ]
    }
   ],
   "source": [
    "if not SUBMISSION:\n",
    "    evaluate(recommended_items, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_results(recommended_items, filename):\n",
    "    print('Printing...')\n",
    "    with open('../submissions/{}'.format(filename), 'w') as output_file:\n",
    "        output_file.write('playlist_id,track_ids\\n')\n",
    "        for index, recommendation in recommended_items.iterrows():\n",
    "            row = '{},'.format(int(recommendation['playlist_id']))\n",
    "            for track_id in pd.Series(recommendation['recommendation']).values:\n",
    "                row += ' {}'.format(track_id)\n",
    "            row += '\\n'\n",
    "            output_file.write(row)\n",
    "print_results(recommended_items, filename=SUBMISSION_FILENAME if SUBMISSION else TEST_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
